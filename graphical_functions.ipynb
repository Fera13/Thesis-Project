{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from kneed import KneeLocator\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_eps(coordinates, min_samples=2):\n",
    "    \"\"\"\n",
    "    Automatically calculates the eps parameter for DBSCAN based on the nearest neighbors.\n",
    "\n",
    "    Args:\n",
    "    coordinates: List of (latitude, longitude) tuples for the cities.\n",
    "    min_samples: The minimum samples in a neighborhood for a point to be considered as a core point.\n",
    "\n",
    "    Returns:\n",
    "    The calculated eps value.\n",
    "    \"\"\"\n",
    "    # Use NearestNeighbors to find the distance to the nearest min_samples points\n",
    "    nn = NearestNeighbors(n_neighbors=min_samples)\n",
    "    nn.fit(coordinates)\n",
    "    distances, indices = nn.kneighbors(coordinates)\n",
    "\n",
    "    # Take the distance to the farthest of the min_samples points\n",
    "    distances = np.sort(distances[:, min_samples - 1], axis=0)\n",
    "\n",
    "    # Find the \"knee\" in the distances graph which is a good estimate for eps\n",
    "    knee_locator = KneeLocator(\n",
    "        range(len(distances)), distances, curve=\"convex\", direction=\"increasing\"\n",
    "    )\n",
    "    eps = distances[knee_locator.knee] if knee_locator.knee else np.mean(distances)\n",
    "\n",
    "    return eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perimeter_and_area(points):\n",
    "    \"\"\"\n",
    "    Calculate the perimeter and the area of the convex hull of a set of points.\n",
    "\n",
    "    Args:\n",
    "    points: An array of points in the format [(x1, y1), (x2, y2), ...]\n",
    "\n",
    "    Returns:\n",
    "    The perimeter of the convex hull and the area of the given points.\n",
    "    \"\"\"\n",
    "    if len(points) < 3:\n",
    "        # Not enough points to form a convex hull; return 0\n",
    "        return np.nan, np.nan  # Use NaN to indicate the value is not available\n",
    "\n",
    "    # Ensure all points do not lie on a single line or are not identical\n",
    "    if np.std(points[:, 0]) == 0 or np.std(points[:, 1]) == 0:\n",
    "        return np.nan, np.nan  # Points are collinear or identical in one dimension\n",
    "\n",
    "    try:\n",
    "        hull = ConvexHull(points)\n",
    "        perimeter = hull.area\n",
    "        area = hull.volume\n",
    "        return perimeter, area\n",
    "    except Exception as e:\n",
    "        print(\"Failed to compute ConvexHull:\", e)\n",
    "        return np.nan, np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan_and_metrics(coordinates):\n",
    "    \"\"\"\n",
    "    Performs DBSCAN clustering on the provided coordinates and calculates various metrics for each cluster.\n",
    "\n",
    "    This function automatically calculates the 'eps' parameter for DBSCAN using the nearest neighbors approach,\n",
    "    performs the clustering, and then calculates metrics such as silhouette score, cluster sizes, inter-cluster distances,\n",
    "    and various geometric properties of the clusters like perimeter and area.\n",
    "\n",
    "    Args:\n",
    "        coordinates (dict): A dictionary with city names as keys and (latitude, longitude) tuples as values.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing:\n",
    "            - 'DBSCAN_min_sample': the min_sample value chosen for DBSCAN,\n",
    "            - 'DBSCAN_eps': the epsilon value calculated for DBSCAN,\n",
    "            - 'cluster_IDs': An array of cluster labels for each point.\n",
    "            - 'cluster_sizes': A list with the size (number of points) of each cluster.\n",
    "            - 'n_clusters': The number of clusters found, excluding noise.\n",
    "            - 'avg_inter_cluster_distance_km': The average distance between clusters in kilometers.\n",
    "            - 'min_inter_cluster_distance_km': The minimum distance between any two clusters in kilometers.\n",
    "            - 'max_inter_cluster_distance_km': The maximum distance between any two clusters in kilometers.\n",
    "            - 'average_silhouette': The average silhouette score across all clusters.\n",
    "            - 'n_noise_points': The number of points classified as noise.\n",
    "            - 'std_dev_cluster_sizes': The standard deviation of the sizes of the clusters.\n",
    "            - 'average_cluster_density': The average density of clusters, defined as size/area.\n",
    "            - 'average_cluster_perimeter': The average perimeter of the clusters.\n",
    "            - 'average_cluster_area': The average area of the clusters.\n",
    "            - 'average_cluster_complexity': An average measure of cluster complexity, defined as perimeter/sqrt(area).\n",
    "            - 'eps_exec_time': The execution time for calculating the epsilon value\n",
    "    \"\"\"\n",
    "    if not coordinates:\n",
    "        print(\"No coordinates provided for clustering.\")\n",
    "        return {}\n",
    "\n",
    "    # Convert city coordinates to a NumPy array for DBSCAN\n",
    "    X = np.array(list(coordinates.values()))\n",
    "    if X.size == 0:\n",
    "        print(\"Empty coordinate array.\")\n",
    "        return {}\n",
    "\n",
    "    min_sample = 4  # Based on https://www.theaidream.com/post/dbscan-clustering-algorithm-in-machine-learning 2.dim\n",
    "    start_time_eps = time.time()\n",
    "    # Calculate eps automatically\n",
    "    eps = calculate_eps(X, min_samples=min_sample)\n",
    "    execution_time_eps = time.time() - start_time_eps\n",
    "\n",
    "    # Perform DBSCAN clustering\n",
    "    db = DBSCAN(eps=eps, min_samples=min_sample, metric=\"euclidean\").fit(X)\n",
    "    labels = db.labels_\n",
    "\n",
    "    # Number of clusters, excluding noise if present\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "\n",
    "    # Calculate silhouette score\n",
    "    if n_clusters_ == 0:\n",
    "        print(\"No clusters found.\")\n",
    "        return {\n",
    "            \"DBSCAN_min_sample\": min_sample,\n",
    "            \"DBSCAN_eps\": eps,\n",
    "            \"cluster_IDs\": [],\n",
    "            \"cluster_sizes\": [],\n",
    "            \"n_clusters\": 0,\n",
    "            \"n_noise_points\": n_noise_,\n",
    "            \"avg_inter_cluster_distance_km\": np.nan,\n",
    "            \"min_inter_cluster_distance_km\": np.nan,\n",
    "            \"max_inter_cluster_distance_km\": np.nan,\n",
    "            \"average_silhouette\": np.nan,\n",
    "            \"std_dev_cluster_sizes\": std_dev_cluster_sizes,\n",
    "            \"avg_cluster_density\": np.nan,\n",
    "            \"avg_cluster_perimeter\": np.nan,\n",
    "            \"avg_cluster_area\": np.nan,\n",
    "            \"avg_cluster_complexity\": np.nan,\n",
    "            \"eps_exec_time\": execution_time_eps,\n",
    "        }\n",
    "    elif n_clusters_ > 1:\n",
    "        silhouette_avg = silhouette_score(X, labels)\n",
    "    else:\n",
    "        silhouette_avg = (\n",
    "            np.nan\n",
    "        )  # silhouette score is not meaningful with 1 or 0 clusters\n",
    "\n",
    "    # Prepare cluster information\n",
    "    clusters = [X[labels == i] for i in range(n_clusters_)]\n",
    "    cluster_sizes = [len(cluster) for cluster in clusters]\n",
    "    std_dev_cluster_sizes = np.std(cluster_sizes) if cluster_sizes else 0\n",
    "\n",
    "    # Calculate inter-cluster distances\n",
    "    cluster_centers = [np.mean(cluster, axis=0) for cluster in clusters]\n",
    "    if len(cluster_centers) > 1:\n",
    "        inter_cluster_distances = (\n",
    "            pdist(cluster_centers, \"euclidean\") * 111\n",
    "        )  # Approx. conversion from degrees to km\n",
    "        avg_inter_cluster_distance = np.mean(inter_cluster_distances)\n",
    "        min_inter_cluster_distance = np.min(inter_cluster_distances)\n",
    "        max_inter_cluster_distance = np.max(inter_cluster_distances)\n",
    "    else:\n",
    "        avg_inter_cluster_distance = min_inter_cluster_distance = (\n",
    "            max_inter_cluster_distance\n",
    "        ) = np.nan\n",
    "\n",
    "    cluster_perimeters, cluster_areas = zip(\n",
    "        *[calculate_perimeter_and_area(cluster) for cluster in clusters]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"DBSCAN_min_sample\": min_sample,\n",
    "        \"DBSCAN_eps\": eps,\n",
    "        \"cluster_IDs\": labels,\n",
    "        \"cluster_sizes\": cluster_sizes,\n",
    "        \"n_clusters\": n_clusters_,\n",
    "        \"n_noise_points\": n_noise_,\n",
    "        \"avg_inter_cluster_distance_km\": avg_inter_cluster_distance,\n",
    "        \"min_inter_cluster_distance_km\": min_inter_cluster_distance,\n",
    "        \"max_inter_cluster_distance_km\": max_inter_cluster_distance,\n",
    "        \"avg_silhouette\": silhouette_avg,\n",
    "        \"std_dev_cluster_sizes\": std_dev_cluster_sizes,\n",
    "        \"avg_cluster_density\": np.mean(\n",
    "            [\n",
    "                size / area if area else 0\n",
    "                for size, area in zip(cluster_sizes, cluster_areas)\n",
    "            ]\n",
    "        ),\n",
    "        \"avg_cluster_perimeter\": (\n",
    "            np.mean(cluster_perimeters) if cluster_perimeters else np.nan\n",
    "        ),\n",
    "        \"avg_cluster_area\": np.mean(cluster_areas) if cluster_areas else np.nan,\n",
    "        \"avg_cluster_complexity\": np.mean(\n",
    "            [\n",
    "                perimeter / np.sqrt(area) if area else 0\n",
    "                for perimeter, area in zip(cluster_perimeters, cluster_areas)\n",
    "            ]\n",
    "        ),\n",
    "        \"eps_exec_time\": execution_time_eps,\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
